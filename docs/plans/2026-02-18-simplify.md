# Simplification Implementation Plan

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** Reduce code duplication and improve clarity — consolidate retry logic, extract scan loop to its own module, replace background repair polling with on-demand repair at STRM access time.

**Architecture:** Single `fetch_with_retry` in `rd_client.rs` accepts a `terminal_statuses` slice. A new `tasks.rs` owns the scan loop. `dav_fs.rs` re-unrestricts links on read and spawns repair on 503, removing the need for a background repair loop entirely.

**Tech Stack:** Rust, tokio, reqwest, dav-server, sled, hyper

**Design doc:** `docs/plans/2026-02-18-simplify-design.md`

---

### Task 1: Consolidate retry helpers and three variants into one in `rd_client.rs`

**Files:**
- Modify: `src/rd_client.rs`

**Context:** There are three near-identical private async methods — `fetch_with_retry`, `fetch_with_retry_except_503`, `fetch_with_retry_except_404` — differing only in which status codes abort immediately without retrying. There are also three helper methods whose names don't read clearly. Replace all three variants with one method; rename the helpers.

**Step 1: Rename the three helpers in-place**

In `src/rd_client.rs`, make these three renames (use find-and-replace within the file):

| Old name | New name |
|---|---|
| `apply_backoff` | `backoff_delay` |
| `handle_retryable_status` | `wait_for_retry` |
| `is_retryable_status` | `should_retry_status` |

`apply_backoff` / `backoff_delay` is a free async fn (no `self`), called as `Self::apply_backoff(attempt).await`. Update both the `fn` definition and all three call sites.

**Step 2: Replace the three `fetch_with_retry_*` methods with one**

Delete `fetch_with_retry_except_503` and `fetch_with_retry_except_404` entirely.

Replace the body of `fetch_with_retry` with:

```rust
async fn fetch_with_retry<T, F>(
    &self,
    make_request: F,
    terminal_statuses: &[reqwest::StatusCode],
) -> Result<T, reqwest::Error>
where
    T: serde::de::DeserializeOwned,
    F: Fn() -> reqwest::RequestBuilder,
{
    let mut last_error: Option<reqwest::Error> = None;
    let max_attempts = 10;

    for attempt in 1..=max_attempts {
        Self::backoff_delay(attempt).await;
        self.rate_limit().await;

        match make_request().send().await {
            Ok(resp) => {
                let status = resp.status();

                if terminal_statuses.contains(&status) {
                    return resp.error_for_status()?.json().await;
                }

                if Self::should_retry_status(status) {
                    Self::wait_for_retry(status, resp.headers(), attempt, max_attempts).await;
                }

                match resp.error_for_status() {
                    Ok(resp) => {
                        let headers = resp.headers().clone();
                        let text = resp.text().await?;
                        if text.trim().is_empty() || status.as_u16() == 204 {
                            if let Ok(val) = serde_json::from_str::<T>("[]") {
                                return Ok(val);
                            }
                            warn!("RD API empty body or 204 (attempt {}/{}). Status: {}, Headers: {:?}",
                                attempt, max_attempts, status, headers);
                            continue;
                        }
                        match serde_json::from_str::<T>(&text) {
                            Ok(val) => return Ok(val),
                            Err(e) => {
                                error!("Failed to decode RD response: {}. Status: {}, Body: {}, Headers: {:?}",
                                    e, status, text, headers);
                            }
                        }
                    }
                    Err(e) => {
                        warn!("RD API error (attempt {}/{}): {}. Status: {}", attempt, max_attempts, e, status);
                        last_error = Some(e);
                    }
                }
            }
            Err(e) => {
                warn!("RD API request failed (attempt {}/{}): {}", attempt, max_attempts, e);
                last_error = Some(e);
            }
        }
    }

    if let Some(e) = last_error {
        Err(e)
    } else {
        make_request().send().await?.error_for_status()?.json().await
    }
}
```

**Step 3: Update all callers of the old variants**

In `get_torrent_info`, change:
```rust
self.fetch_with_retry_except_404(|| self.client.get(&url)).await
```
to:
```rust
self.fetch_with_retry(|| self.client.get(&url), &[reqwest::StatusCode::NOT_FOUND]).await
```

In `unrestrict_link`, change:
```rust
let response: UnrestrictResponse = self.fetch_with_retry_except_503(|| {
    self.client.post(url).form(&[("link", link)])
}).await?;
```
to:
```rust
let response: UnrestrictResponse = self.fetch_with_retry(
    || self.client.post(url).form(&[("link", link)]),
    &[reqwest::StatusCode::SERVICE_UNAVAILABLE],
).await?;
```

In `get_torrents`, `add_magnet`, `select_files` — change their existing `fetch_with_retry(...)` calls to pass `&[]` as the second argument:
```rust
self.fetch_with_retry(|| self.client.get(&url), &[]).await
```

**Step 4: Build**

```bash
cargo build
```

Expected: compiles with no errors. `check_link_health` still exists and is unused — that's fine for now.

**Step 5: Commit**

```bash
git add src/rd_client.rs
git commit -m "refactor(rd_client): consolidate retry variants into single fetch_with_retry"
```

---

### Task 2: Remove `check_torrent_health` and `RepairState::Checking` from `repair.rs`; add `repair_by_id`

**Files:**
- Modify: `src/repair.rs`

**Context:** The background repair loop (which called `check_torrent_health`) is being deleted. `RepairState::Checking` was only used by that method. We add `repair_by_id` so `dav_fs.rs` can trigger repair with just a torrent ID.

**Step 1: Remove `RepairState::Checking`**

Change:
```rust
pub enum RepairState {
    Healthy,
    Checking,
    Broken,
    Repairing,
    Failed,
}
```
to:
```rust
pub enum RepairState {
    Healthy,
    Broken,
    Repairing,
    Failed,
}
```

**Step 2: Delete the `check_torrent_health` method**

Remove the entire `pub async fn check_torrent_health(...)` method (~130 lines, from the `pub async fn check_torrent_health` signature down to and including its closing `}`).

**Step 3: Add `repair_by_id`**

Add this method to `impl RepairManager`, just before `should_hide_torrent`:

```rust
/// Fetch torrent info fresh and attempt repair. Called on-demand when a broken
/// link is detected at STRM access time.
pub async fn repair_by_id(&self, torrent_id: &str) -> Result<(), String> {
    match self.rd_client.get_torrent_info(torrent_id).await {
        Ok(info) => self.repair_torrent(&info).await,
        Err(e) => Err(format!("Failed to fetch torrent info for repair: {}", e)),
    }
}
```

**Step 4: Build**

```bash
cargo build
```

Expected: compiles. `check_link_health` in `rd_client.rs` is now unused — compiler may warn but won't error.

**Step 5: Commit**

```bash
git add src/repair.rs
git commit -m "refactor(repair): remove check_torrent_health and Checking state; add repair_by_id"
```

---

### Task 3: Remove `check_link_health` from `rd_client.rs`

**Files:**
- Modify: `src/rd_client.rs`

**Context:** `check_link_health` was only called by `check_torrent_health`, which was deleted in Task 2. It's now dead code.

**Step 1: Delete `check_link_health`**

Remove the entire `pub async fn check_link_health(...)` method (~70 lines).

**Step 2: Build and test**

```bash
cargo build && cargo test
```

Expected: compiles cleanly, all non-ignored tests pass.

**Step 3: Commit**

```bash
git add src/rd_client.rs
git commit -m "refactor(rd_client): remove unused check_link_health"
```

---

### Task 4: Skip files with broken links in `vfs.rs`

**Files:**
- Modify: `src/vfs.rs`

**Context:** Currently, when `unrestrict_link` fails at VFS build time, a placeholder string `"# Error: Failed to unrestrict link\n"` is stored as the STRM content. This causes Jellyfin to see a file that looks valid but plays nothing. Instead, skip the file so it simply doesn't appear in the listing.

**Step 1: Change error handling in `add_path_to_tree`**

In `src/vfs.rs`, find the `add_path_to_tree` method. Locate the `unrestrict_link` call:

```rust
let strm_content = match rd_client.unrestrict_link(&link).await {
    Ok(response) => {
        let url = response.download;
        tracing::debug!("Unrestricted link for {}: {}", final_name, url);
        format!("{}\n", url).into_bytes()
    }
    Err(e) => {
        tracing::error!("Failed to unrestrict link for {}: {}", final_name, e);
        // Use a placeholder URL if unrestricting fails
        // This shouldn't happen for healthy torrents, but prevents VFS build failure
        "# Error: Failed to unrestrict link\n".to_string().into_bytes()
    }
};
```

Replace with:

```rust
let strm_content = match rd_client.unrestrict_link(&link).await {
    Ok(response) => {
        let url = response.download;
        tracing::debug!("Unrestricted link for {}: {}", final_name, url);
        format!("{}\n", url).into_bytes()
    }
    Err(e) => {
        tracing::warn!("Skipping file {} — unrestrict failed: {}", final_name, e);
        return;
    }
};
```

**Step 2: Build**

```bash
cargo build
```

Expected: compiles cleanly.

**Step 3: Commit**

```bash
git add src/vfs.rs
git commit -m "fix(vfs): skip files where unrestrict fails instead of inserting broken placeholder"
```

---

### Task 5: On-demand re-unrestrict and repair in `dav_fs.rs`

**Files:**
- Modify: `src/dav_fs.rs`

**Context:** Currently `StrmFile` serves pre-resolved content stored at VFS build time. We want it to re-unrestrict on every read (the 1-hour cache in `RealDebridClient` makes this free when healthy), return a fresh URL, and trigger repair if it gets a 503. This catches links that were healthy at scan time but broke since.

**Step 1: Add `rd_client` and `rd_link` to `StrmFile`**

Find the private `StrmFile` struct:
```rust
struct StrmFile {
    name: String,
    content: Bytes,
    rd_torrent_id: String,
    repair_manager: Arc<RepairManager>,
    pos: u64,
}
```

Replace with:
```rust
struct StrmFile {
    name: String,
    content: Bytes,        // pre-resolved URL — used only for len() in metadata
    rd_link: String,       // raw RD link — re-unrestricted on every read
    rd_torrent_id: String,
    repair_manager: Arc<RepairManager>,
    rd_client: Arc<RealDebridClient>,
    pos: u64,
}
```

Add the import at the top of `dav_fs.rs` if not already present:
```rust
use crate::rd_client::RealDebridClient;
```

**Step 2: Pass `rd_link` and `rd_client` when constructing `StrmFile` in `open()`**

Find the match arm in `DavFileSystem::open`:
```rust
VfsNode::StrmFile { name, strm_content, rd_torrent_id, .. } => {
    Ok(Box::new(StrmFile {
        name,
        content: Bytes::from(strm_content),
        rd_torrent_id,
        repair_manager: self.repair_manager.clone(),
        pos: 0,
    }) as Box<dyn DavFile>)
}
```

Replace with:
```rust
VfsNode::StrmFile { name, strm_content, rd_link, rd_torrent_id } => {
    Ok(Box::new(StrmFile {
        name,
        content: Bytes::from(strm_content),
        rd_link,
        rd_torrent_id,
        repair_manager: self.repair_manager.clone(),
        rd_client: self.rd_client.clone(),
        pos: 0,
    }) as Box<dyn DavFile>)
}
```

**Step 3: Replace `read_bytes` with on-demand unrestrict + repair**

Find `read_bytes` on `StrmFile` (the `impl DavFile for StrmFile` block):

```rust
fn read_bytes(&mut self, len: usize) -> FsFuture<'_, Bytes> {
    async move {
        // Check if torrent is under repair
        if self.repair_manager.should_hide_torrent(&self.rd_torrent_id).await {
            return Err(FsError::GeneralFailure);
        }

        // Read from stored content
        if self.pos >= self.content.len() as u64 {
            return Ok(Bytes::new());
        }

        let start = self.pos as usize;
        let end = std::cmp::min(start + len, self.content.len());
        let data = self.content.slice(start..end);

        self.pos += data.len() as u64;
        Ok(data)
    }.boxed()
}
```

Replace with:

```rust
fn read_bytes(&mut self, len: usize) -> FsFuture<'_, Bytes> {
    async move {
        if self.repair_manager.should_hide_torrent(&self.rd_torrent_id).await {
            return Err(FsError::GeneralFailure);
        }

        // Re-unrestrict for a fresh URL. The 1-hour cache in RealDebridClient
        // makes this a no-op in the common healthy case.
        match self.rd_client.unrestrict_link(&self.rd_link).await {
            Ok(response) => {
                let content = Bytes::from(format!("{}\n", response.download));
                if self.pos >= content.len() as u64 {
                    return Ok(Bytes::new());
                }
                let start = self.pos as usize;
                let end = std::cmp::min(start + len, content.len());
                let data = content.slice(start..end);
                self.pos += data.len() as u64;
                Ok(data)
            }
            Err(e) => {
                tracing::error!("Re-unrestrict failed for {} — triggering repair: {}", self.name, e);
                let repair_manager = self.repair_manager.clone();
                let torrent_id = self.rd_torrent_id.clone();
                let link = self.rd_link.clone();
                repair_manager.mark_broken(&torrent_id, &link).await;
                tokio::spawn(async move {
                    if let Err(e) = repair_manager.repair_by_id(&torrent_id).await {
                        tracing::error!("Repair failed for {}: {}", torrent_id, e);
                    }
                });
                Err(FsError::GeneralFailure)
            }
        }
    }.boxed()
}
```

**Step 4: Build**

```bash
cargo build
```

Expected: compiles cleanly.

**Step 5: Commit**

```bash
git add src/dav_fs.rs
git commit -m "feat(dav_fs): re-unrestrict on read and trigger on-demand repair on 503"
```

---

### Task 6: Create `src/tasks.rs` with the scan loop

**Files:**
- Create: `src/tasks.rs`

**Context:** The scan loop currently lives as an 80-line inline `tokio::spawn` block in `main.rs`. Moving it to its own function in `tasks.rs` makes `main.rs` readable at a glance and the scan logic independently understandable.

**Step 1: Create `src/tasks.rs`**

Create the file with the following content. This is the scan loop body extracted verbatim from `main.rs`, wrapped in a named async function:

```rust
use std::collections::HashMap;
use std::sync::Arc;
use std::time::Duration;
use tokio::sync::RwLock;
use tracing::{info, warn, error};
use futures_util::StreamExt;
use crate::rd_client::RealDebridClient;
use crate::tmdb_client::TmdbClient;
use crate::vfs::{DebridVfs, MediaMetadata};
use crate::identification::identify_torrent;
use crate::repair::RepairManager;

pub async fn run_scan_loop(
    rd_client: Arc<RealDebridClient>,
    tmdb_client: Arc<TmdbClient>,
    vfs: Arc<RwLock<DebridVfs>>,
    db_tree: sled::Tree,
    repair_manager: Arc<RepairManager>,
    interval_secs: u64,
) {
    let mut seen_torrents: HashMap<String, (crate::rd_client::TorrentInfo, MediaMetadata)> =
        HashMap::new();

    // Load persisted matches from DB on startup
    for result in db_tree.iter().flatten() {
        let (id_bytes, data_bytes) = result;
        let id = String::from_utf8_lossy(&id_bytes).to_string();
        if let Ok(data) = serde_json::from_slice::<(crate::rd_client::TorrentInfo, MediaMetadata)>(&data_bytes) {
            seen_torrents.insert(id, data);
        }
    }
    if !seen_torrents.is_empty() {
        info!("Loaded {} persistent matches from database.", seen_torrents.len());
    }

    info!("Scan task: running initial scan immediately");

    loop {
        info!("Refreshing torrent list...");
        match rd_client.get_torrents().await {
            Ok(torrents) => {
                if torrents.is_empty() {
                    warn!("No torrents found in Real Debrid account.");
                }
                let mut current_data = Vec::new();
                let mut to_identify = Vec::new();
                for torrent in &torrents {
                    if torrent.status == "downloaded" {
                        if let Some(data) = seen_torrents.get(&torrent.id) {
                            current_data.push(data.clone());
                        } else if let Ok(Some(data_bytes)) = db_tree.get(&torrent.id) {
                            if let Ok(data) = serde_json::from_slice::<(crate::rd_client::TorrentInfo, MediaMetadata)>(&data_bytes) {
                                seen_torrents.insert(torrent.id.clone(), data.clone());
                                current_data.push(data);
                            } else {
                                to_identify.push(torrent.clone());
                            }
                        } else {
                            to_identify.push(torrent.clone());
                        }
                    }
                }

                if !to_identify.is_empty() {
                    info!("Identifying {} new torrents...", to_identify.len());
                    let mut stream = futures_util::stream::iter(to_identify)
                        .map(|torrent| {
                            let rd_client = rd_client.clone();
                            let tmdb_client = tmdb_client.clone();
                            async move {
                                match rd_client.get_torrent_info(&torrent.id).await {
                                    Ok(info) => {
                                        let metadata = identify_torrent(&info, &tmdb_client).await;
                                        Ok::<(String, crate::rd_client::TorrentInfo, MediaMetadata), reqwest::Error>(
                                            (torrent.id, info, metadata)
                                        )
                                    }
                                    Err(e) => Err(e),
                                }
                            }
                        })
                        .buffer_unordered(1);

                    let new_total = torrents.iter()
                        .filter(|t| t.status == "downloaded" && !seen_torrents.contains_key(&t.id))
                        .count();
                    let mut processed_new = 0;

                    while let Some(result) = stream.next().await {
                        processed_new += 1;
                        match result {
                            Ok((id, info, metadata)) => {
                                seen_torrents.insert(id.clone(), (info.clone(), metadata.clone()));
                                if let Ok(data_bytes) = serde_json::to_vec(&(info.clone(), metadata.clone())) {
                                    let _ = db_tree.insert(id, data_bytes);
                                }
                                current_data.push((info, metadata));
                            }
                            Err(e) => error!("Failed to identify torrent: {}", e),
                        }
                        if processed_new % 10 == 0 || processed_new == new_total {
                            info!("Progress: {}/{} new torrents identified", processed_new, new_total);
                            update_vfs(&vfs, &current_data, &repair_manager, &rd_client).await;
                        }
                    }
                } else {
                    update_vfs(&vfs, &current_data, &repair_manager, &rd_client).await;
                }

                let current_ids: std::collections::HashSet<String> =
                    torrents.iter().map(|t| t.id.clone()).collect();
                seen_torrents.retain(|id, _| current_ids.contains(id));
                info!("VFS update complete.");
            }
            Err(e) => error!("Failed to get torrents: {}", e),
        }

        info!("Scan task: sleeping {}s until next scan", interval_secs);
        tokio::time::sleep(Duration::from_secs(interval_secs)).await;
    }
}

async fn update_vfs(
    vfs: &Arc<RwLock<DebridVfs>>,
    current_data: &[(crate::rd_client::TorrentInfo, MediaMetadata)],
    repair_manager: &Arc<RepairManager>,
    rd_client: &Arc<RealDebridClient>,
) {
    let mut filtered = Vec::new();
    for (torrent_info, metadata) in current_data {
        if !repair_manager.should_hide_torrent(&torrent_info.id).await {
            filtered.push((torrent_info.clone(), metadata.clone()));
        }
    }
    let mut vfs_lock = vfs.write().await;
    vfs_lock.update(filtered, rd_client.clone()).await;
}
```

**Step 2: Build**

The module isn't declared yet so this won't be compiled — just check it parses:

```bash
cargo build
```

Expected: compiles (tasks.rs not yet wired in, so no errors yet — Rust only compiles declared modules).

---

### Task 7: Wire `tasks.rs` into `mapper.rs` and shrink `main.rs`

**Files:**
- Modify: `src/mapper.rs`
- Modify: `src/main.rs`

**Step 1: Add `pub mod tasks` to `mapper.rs` and remove dead code**

Open `src/mapper.rs`. The file currently has a module block and a `run_full_scan` function that's never called.

Replace the entire file with:

```rust
pub mod rd_client;
pub mod vfs;
pub mod dav_fs;
pub mod tmdb_client;
pub mod identification;
pub mod repair;
pub mod tasks;
```

**Step 2: Replace `main.rs` scan spawn and remove repair spawn**

Open `src/main.rs`. Delete:
- The entire repair `tokio::spawn` block (lines 53–109 approximately)
- The entire scan `tokio::spawn` block (lines 112–235 approximately)
- All imports that were only used by those blocks: `futures_util::StreamExt`, the inline `debridmoviemapper::vfs::MediaMetadata` usage

Replace both spawns with:

```rust
tokio::spawn(debridmoviemapper::tasks::run_scan_loop(
    rd_client.clone(),
    tmdb_client.clone(),
    vfs.clone(),
    tree.clone(),
    repair_manager.clone(),
    scan_interval_secs,
));
```

Also remove `repair_interval_secs` parsing and its log lines (no longer needed).

The final `main.rs` should look like:

```rust
use std::sync::Arc;
use tokio::sync::RwLock;
use tracing::info;
use debridmoviemapper::rd_client::RealDebridClient;
use debridmoviemapper::vfs::DebridVfs;
use debridmoviemapper::dav_fs::DebridFileSystem;
use debridmoviemapper::tmdb_client::TmdbClient;
use debridmoviemapper::repair::RepairManager;
use dav_server::DavHandler;
use hyper::server::conn::http1;
use hyper_util::rt::TokioIo;
use tokio::net::TcpListener;
use std::net::SocketAddr;
use hyper::service::service_fn;
use hyper::Request;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    dotenvy::dotenv().ok();
    tracing_subscriber::fmt::init();

    let api_token = std::env::var("RD_API_TOKEN")
        .expect("RD_API_TOKEN must be set")
        .trim()
        .to_string();
    let tmdb_api_key = std::env::var("TMDB_API_KEY")
        .expect("TMDB_API_KEY must be set")
        .trim()
        .to_string();
    let scan_interval_secs = std::env::var("SCAN_INTERVAL_SECS")
        .ok()
        .and_then(|s| s.parse::<u64>().ok())
        .unwrap_or(60);

    info!("Scan interval: {}s", scan_interval_secs);

    let rd_client = Arc::new(RealDebridClient::new(api_token));
    let tmdb_client = Arc::new(TmdbClient::new(tmdb_api_key));
    let vfs = Arc::new(RwLock::new(DebridVfs::new()));
    let repair_manager = Arc::new(RepairManager::new(rd_client.clone()));

    let db = sled::open("metadata.db").expect("Failed to open database");
    let tree = db.open_tree("matches").expect("Failed to open database tree");

    tokio::spawn(debridmoviemapper::tasks::run_scan_loop(
        rd_client.clone(),
        tmdb_client.clone(),
        vfs.clone(),
        tree.clone(),
        repair_manager.clone(),
        scan_interval_secs,
    ));

    let dav_fs = DebridFileSystem::new(rd_client.clone(), vfs.clone(), repair_manager.clone());
    let dav_handler = DavHandler::builder()
        .filesystem(Box::new(dav_fs))
        .locksystem(dav_server::fakels::FakeLs::new())
        .build_handler();

    let addr = SocketAddr::from(([0, 0, 0, 0], 8080));
    let listener = TcpListener::bind(addr).await?;
    info!("WebDAV server listening on http://{}", addr);

    loop {
        let (stream, _addr) = listener.accept().await?;
        let io = TokioIo::new(stream);
        let dav_handler = dav_handler.clone();

        tokio::task::spawn(async move {
            if let Err(err) = http1::Builder::new()
                .serve_connection(io, service_fn(move |req: Request<hyper::body::Incoming>| {
                    let dav_handler = dav_handler.clone();
                    async move {
                        Ok::<_, hyper::Error>(dav_handler.handle(req).await)
                    }
                }))
                .await
            {
                use std::error::Error;
                if let Some(io_err) = err.source().and_then(|s| s.downcast_ref::<std::io::Error>()) {
                    if matches!(io_err.kind(), std::io::ErrorKind::ConnectionReset | std::io::ErrorKind::BrokenPipe) {
                        return;
                    }
                }
                if format!("{:?}", err).contains("IncompleteMessage") {
                    return;
                }
                tracing::error!("Error serving connection: {:?}", err);
            }
        });
    }
}
```

**Step 3: Build and test**

```bash
cargo build && cargo test
```

Expected: compiles cleanly, all non-ignored tests pass.

**Step 4: Commit**

```bash
git add src/mapper.rs src/main.rs src/tasks.rs
git commit -m "refactor: extract scan loop to tasks.rs; remove repair background loop; shrink main.rs"
```

---

## Verification

After all tasks are complete:

```bash
# Full build
cargo build --release

# Run unit tests (no API key needed)
cargo test test_is_generic_title
cargo test test_nfo_generation

# Integration tests (require TMDB_API_KEY)
TMDB_API_KEY=<key> cargo test -- --include-ignored
```

Manual smoke test with Docker:
```bash
touch metadata.db rclone.conf
RD_API_TOKEN=<token> TMDB_API_KEY=<key> cargo run
# Mount via rclone or Jellyfin and verify .strm files play
```
